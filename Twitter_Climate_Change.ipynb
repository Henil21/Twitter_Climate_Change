{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1IgeHBb5FB03WqLnPP-kSxHpyWf4Epv_t",
      "authorship_tag": "ABX9TyOqph/EI5PRp+cYBU7Tgd4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Henil21/Twitter_Climate_Change/blob/main/Twitter_Climate_Change.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D7lHWtUipl5j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Data Ready üå¥"
      ],
      "metadata": {
        "id": "u2ieRL6Xt1Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data=pd.read_csv('/content/drive/MyDrive/twitter_sentiment_data.csv')\n",
        "Data['sentiment'] = Data['sentiment'].replace(-1, 3)\n",
        "\n",
        "# Write the modified DataFrame back to a new CSV file or overwrite the existing one\n"
      ],
      "metadata": {
        "id": "OkF0pW-Rsq_t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "message=Data['message']\n",
        "message[10]\n",
        "sentiment=Data['sentiment']\n",
        "print(f\"message\\n{message[10]}\\n\\nsentiment : {sentiment[10]}\\n\\n\")\n",
        "print(f\"number of data : {len(message)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33kO0mZWs0cs",
        "outputId": "e9de3b21-f788-4ca8-fcbc-19bda248546c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message\n",
            "RT @DrDeJarnett: It's vital that the public health community addresses climate change- via @Climate4Health's Tabola #APHA2016 https://t.co/√É¬¢√¢‚Äö¬¨√Ç¬¶\n",
            "\n",
            "sentiment : 1\n",
            "\n",
            "\n",
            "number of data : 43943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMquEzETxTwm",
        "outputId": "4aa72589-071f-4b98-ffb2-f82ee73c1a3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    22962\n",
              "2     9276\n",
              "0     7715\n",
              "3     3990\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing random tweet üéã"
      ],
      "metadata": {
        "id": "L697yUV4txv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_number=random.randrange(0,len(message)-5)\n",
        "for i in range(seed_number,seed_number+5):\n",
        "    print(f\"T_number : {i}\\n message : {message[i]}\\n Sentiment : {sentiment[i]}\\n\")\n",
        "    print('-----------------------------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpTMvMuuuxLI",
        "outputId": "69a4bcb6-f1f8-40db-e345-e41e96d789ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T_number : 11994\n",
            " message : RT @MichaelEMann: Oh my that's a low bar you've set Elon...\n",
            "RT @elonmusk Tillerson also said that ‚Äúthe risk of climate change does exist‚Äù\n",
            " Sentiment : 1\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "T_number : 11995\n",
            " message : RT @davidcicilline: RT this to remind @POTUS @realDonaldTrump that 2016 was the hottest year on record and climate change is real. https://‚Ä¶\n",
            " Sentiment : 1\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "T_number : 11996\n",
            " message : Concerns global warming 'worse than thought' https://t.co/5xpNmACh4P https://t.co/TM5oF9ZZ7J\n",
            " Sentiment : 1\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "T_number : 11997\n",
            " message : @realDonaldTrump it's too bad you're making most Americans worried about the future of global warming.\n",
            " Sentiment : 1\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "T_number : 11998\n",
            " message : RT @elliegoulding: Talking with you all last night about climate change just reminds me how woke my fans are üòÇ guess it's up to other peopl‚Ä¶\n",
            " Sentiment : 1\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data üå≥"
      ],
      "metadata": {
        "id": "x7-KVIwvzrQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences,val_sentences,train_labels,val_labels=train_test_split(Data[\"message\"].to_numpy(),\n",
        "                                                                       Data[\"sentiment\"].to_numpy(),\n",
        "                                                                       test_size=0.3,\n",
        "                                                                       random_state=42)\n",
        "print(f\"train_sentences : {len(train_sentences)}\\nval_sentences : {len(val_sentences)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spxZkbDnxg9S",
        "outputId": "a9b5e10e-a0ad-4bed-ef25-6e8ccf938509"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentences : 30760\n",
            "val_sentences : 13183\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the average number of token(words) in the training tweet\n",
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxiZXOQMz2H3",
        "outputId": "c6b49915-f3eb-484d-df63-36767b936f58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 17# max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                     split=\"whitespace\",\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "oaG67w-pz_m9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)\n",
        "sample_text='the goverment should propose a uniform policy for climate change'\n",
        "text_vectorizer([sample_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QY3ym0V0GKQ",
        "outputId": "76fbf79f-1970-4d66-c7bf-3d66b1083c51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 17), dtype=int64, numpy=\n",
              "array([[   5,    1,  108, 5630,    9,    1,  252,   15,    2,    3,    0,\n",
              "           0,    0,    0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_voc=text_vectorizer.get_vocabulary()\n",
        "top_5=words_in_voc[:5]\n",
        "bottom_5=words_in_voc[-5:]\n",
        "print(f\"number of word in vocab {len(words_in_voc)}\\n\")\n",
        "print(f\"5 most comman word in  vocab {top_5}\\n\")\n",
        "print(f\"5 least comman  word in vocab {bottom_5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h7crDFg0T4S",
        "outputId": "35e45599-8065-4cae-b16a-e9f2ade1803c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of word in vocab 10000\n",
            "\n",
            "5 most comman word in  vocab ['', '[UNK]', 'climate', 'change', 'rt']\n",
            "\n",
            "5 least comman  word in vocab ['expressed', 'exponentially', 'exploitation', 'explicitly', 'expertise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,#set the input shape\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)"
      ],
      "metadata": {
        "id": "HCxzEBMo0dAZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert text into number\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# our model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),# convert words to number using tfidf\n",
        "    (\"clf\",MultinomialNB())# model the text\n",
        "])\n",
        "# fit the pipleine to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "CFPhbkHA0gCs",
        "outputId": "72eb100f-6ddb-405c-cbbf-605f19fb1b16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baseline_score=model_0.score(val_sentences,val_labels)\n",
        "# as we use .evaluate in tf for sklearn its .score\n",
        "baseline_score*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLXXf_t0jPG",
        "outputId": "e91ffbf6-2d49-4502-dce5-744752baf591"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57.809299855875"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8bbTVck00i0",
        "outputId": "9353c598-ccfa-401e-b70d-8718fc25c9bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@ErrataRob @pvineetha seeing a direct threat to seeds but this is an indication of climate change, which, I think,‚Ä¶ https://t.co/SPZmyDh5Ry',\n",
              "       'RT @Harlina__: @cafedotcom @tedcruz the whole POTUS is a joke . Declining education , climate change and congratulating people for being si‚Ä¶',\n",
              "       '@LibertyUSA1776 @c5hardtop1999 I guarantee you that if you asked any of the refugees none will say $q$climate change$q$ is the reason I left.',\n",
              "       ...,\n",
              "       'Climate Depot:Cl-FI: New Study apes Hollywood: ‚ÄòGlobal warming can trigger a cooling trend‚Äô ‚Äì Climate scientist http://t.co/4ikBwkk0nD',\n",
              "       \"RT @TeslaMotors: Rising temperatures put millions at risk as climate change hotspot @third_pole (world's 3rd-largest store of ice) is melti√É¬¢√¢‚Äö¬¨√Ç¬¶\",\n",
              "       \"RT @RandomSavage3: @FrMatthewLC Crazy how two days ago people were going bezerk about 'global warming' then a blizzard hits\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "inputs=layers.Input(shape=(1,),dtype=\"string\")\n",
        "x=text_vectorizer(inputs)\n",
        "\n",
        "x=embedding(x)\n",
        "x=layers.Bidirectional(layers.GRU(64,return_sequences=True))(x) #layers.Bidirectional works with any LSTM\n",
        "x=layers.GRU(64)(x)\n",
        "outputs=layers.Dense(4,activation=\"softmax\")(x)\n",
        "model_4=tf.keras.Model(inputs,outputs,name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "id": "hxqk8krH0nM6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model_4_history=model_4.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FpllTUJ0tiQ",
        "outputId": "89579926-f1de-4c15-ca64-714c54f158ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "962/962 [==============================] - 41s 30ms/step - loss: 0.8237 - accuracy: 0.6700 - val_loss: 0.6809 - val_accuracy: 0.7221\n",
            "Epoch 2/5\n",
            "962/962 [==============================] - 14s 14ms/step - loss: 0.5532 - accuracy: 0.7851 - val_loss: 0.6882 - val_accuracy: 0.7234\n",
            "Epoch 3/5\n",
            "962/962 [==============================] - 12s 13ms/step - loss: 0.4155 - accuracy: 0.8409 - val_loss: 0.7703 - val_accuracy: 0.7311\n",
            "Epoch 4/5\n",
            "962/962 [==============================] - 13s 14ms/step - loss: 0.3106 - accuracy: 0.8853 - val_loss: 0.8440 - val_accuracy: 0.7203\n",
            "Epoch 5/5\n",
            "962/962 [==============================] - 12s 12ms/step - loss: 0.2337 - accuracy: 0.9156 - val_loss: 0.9534 - val_accuracy: 0.7137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZQw315i61kc",
        "outputId": "3b0e1872-c0ab-45ef-81f8-5f44b47bc16f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed=hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
        "embed_sample=embed([\n",
        "                    \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "\n",
        "embed_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbcxTVbH8Wtx",
        "outputId": "eee7cf6b-2cb6-45c1-ad1e-9d3b3145c6b8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[ 3.59669030e-02, -8.57946724e-02, -1.15274135e-02,\n",
              "         5.25983237e-03, -1.85217280e-02, -5.04201241e-02,\n",
              "        -3.61694060e-02,  5.34677925e-03,  4.80591506e-02,\n",
              "         4.69074398e-02, -3.72333117e-02, -1.14954300e-02,\n",
              "         4.35241461e-02,  7.05099106e-02,  7.09376186e-02,\n",
              "        -8.18042904e-02,  8.71716533e-03, -4.65412140e-02,\n",
              "        -2.24577412e-02,  4.68687154e-02,  2.02256138e-03,\n",
              "         3.09907366e-02,  2.04356425e-02,  6.39216825e-02,\n",
              "        -7.64108524e-02,  8.42117816e-02, -4.57603931e-02,\n",
              "        -1.06165220e-03, -2.05942076e-02,  1.24110505e-02,\n",
              "         5.72753772e-02,  3.81562151e-02, -2.74211336e-02,\n",
              "        -3.54347005e-03, -9.83258486e-02, -1.24485493e-02,\n",
              "         3.86562832e-02,  5.03195487e-02, -2.36250404e-02,\n",
              "         3.21848365e-03,  3.22521329e-02,  7.38092232e-03,\n",
              "         4.47310135e-02, -4.12239181e-03,  1.15160448e-02,\n",
              "         2.83772685e-02,  6.01376989e-04, -5.90335056e-02,\n",
              "        -4.94343881e-03, -6.88529201e-03, -4.12424132e-02,\n",
              "        -2.07703980e-03, -1.77201945e-02, -2.27782149e-02,\n",
              "        -2.42898241e-02,  1.39937950e-02, -5.17674796e-02,\n",
              "         5.97374849e-02,  3.81307453e-02, -3.59316431e-02,\n",
              "         3.09860688e-02,  6.09485852e-03, -4.37487178e-02,\n",
              "        -5.38942628e-02, -4.32431735e-02, -3.92870605e-02,\n",
              "         5.61528467e-02,  3.82245891e-03,  6.57871040e-03,\n",
              "        -4.53821830e-02,  3.96313593e-02, -5.69340773e-03,\n",
              "        -2.00726092e-02,  8.17294195e-02,  4.15083803e-02,\n",
              "         3.72894965e-02, -6.70029223e-02, -5.10404930e-02,\n",
              "        -2.56260093e-02,  1.60032362e-02,  3.81825306e-02,\n",
              "        -8.70014261e-03, -2.34965310e-02,  1.55745707e-02,\n",
              "         5.66765293e-02,  7.38508180e-02,  1.52101656e-02,\n",
              "        -8.41727853e-03, -6.44073784e-02, -5.55147938e-02,\n",
              "         7.97353014e-02,  3.61875421e-03,  6.64433464e-02,\n",
              "         2.87908576e-02, -2.44696811e-02,  2.12148018e-02,\n",
              "        -1.03562608e-01, -4.12506796e-02,  2.98409127e-02,\n",
              "        -9.24953669e-02,  4.00588149e-03,  6.01527095e-02,\n",
              "        -3.41755301e-02,  3.29850018e-02, -4.83456068e-02,\n",
              "        -3.69677991e-02,  1.21584749e-02, -2.31851321e-02,\n",
              "        -4.88560125e-02,  3.28469574e-02, -4.62380052e-02,\n",
              "         3.91754182e-03, -3.57808359e-02, -1.83102172e-02,\n",
              "        -3.70730050e-02,  3.35949846e-02,  5.02074882e-02,\n",
              "        -5.49601614e-02,  4.69865017e-02, -3.31131108e-02,\n",
              "         1.66335106e-02, -3.02660204e-02,  6.20632246e-02,\n",
              "        -4.43871729e-02,  6.67187944e-02, -6.10226393e-03,\n",
              "         3.40605080e-02, -5.00078946e-02,  2.04586796e-03,\n",
              "         3.39132398e-02, -3.10870968e-02, -1.93446297e-02,\n",
              "         7.54030049e-02, -6.52687997e-02,  5.25344424e-02,\n",
              "        -6.12028427e-02, -3.02657485e-02,  4.56585037e-03,\n",
              "        -8.89162719e-02, -4.83766310e-02, -2.00605374e-02,\n",
              "        -3.86418924e-02,  1.66886020e-02, -1.47099104e-02,\n",
              "         1.01379557e-02, -8.22198391e-02,  2.74562333e-02,\n",
              "        -3.86099075e-03, -1.09152691e-02, -5.79520464e-02,\n",
              "         2.82120146e-02, -1.71919242e-02,  3.00881565e-02,\n",
              "         2.37061121e-02, -2.33156444e-03, -2.97772959e-02,\n",
              "         1.91768315e-02,  5.16294166e-02, -1.44551294e-02,\n",
              "         1.86848193e-02, -2.49356646e-02,  3.22919451e-02,\n",
              "         2.82293651e-02, -2.51184031e-02, -1.08434856e-02,\n",
              "         3.01642828e-02,  5.04568336e-04, -2.27955766e-02,\n",
              "         2.47642137e-02,  6.97232485e-02,  6.99916715e-03,\n",
              "        -7.34951114e-03,  9.45000276e-02, -6.13124557e-02,\n",
              "         2.62528565e-02,  3.58930416e-02,  6.17793528e-03,\n",
              "         3.43658626e-02,  1.17269810e-02,  4.01629768e-02,\n",
              "         1.53442742e-02,  4.48108837e-03,  5.02520502e-02,\n",
              "         1.88765321e-02,  3.31166610e-02, -2.70847082e-02,\n",
              "        -6.57291710e-03,  8.24265704e-02,  1.05237216e-02,\n",
              "         3.99747565e-02,  2.82467692e-03, -1.24388682e-02,\n",
              "        -3.28868208e-03, -7.26752803e-02, -1.81358249e-03,\n",
              "        -2.76129451e-02,  6.45669252e-02,  5.02010658e-02,\n",
              "         6.75971657e-02,  9.59103741e-03, -8.90628621e-02,\n",
              "         1.17861051e-02,  2.72054970e-02, -3.41815804e-03,\n",
              "        -8.05912241e-02, -5.22511229e-02, -3.81537713e-03,\n",
              "        -4.17376980e-02, -9.68295895e-03,  3.78751233e-02,\n",
              "        -5.67596592e-02, -2.05952320e-02, -1.14134206e-02,\n",
              "        -2.83810701e-02,  9.09043849e-02,  3.93447524e-04,\n",
              "        -2.67905672e-03,  1.53436768e-03,  6.49558008e-02,\n",
              "         5.22872768e-02,  1.80281550e-02,  1.84829552e-02,\n",
              "         1.61396544e-02,  5.27072251e-02, -4.12999056e-02,\n",
              "        -4.80412953e-02, -2.36369148e-02, -2.67371386e-02,\n",
              "         3.93584110e-02,  7.55006773e-03, -6.21337965e-02,\n",
              "        -1.67872645e-02,  1.47809472e-03, -5.64959757e-02,\n",
              "         5.52060977e-02, -1.27273276e-02,  1.03164583e-01,\n",
              "        -1.69769358e-02, -2.17627622e-02, -1.17612239e-02,\n",
              "         1.40765775e-02, -1.40489684e-02,  6.19004816e-02,\n",
              "        -3.57006788e-02,  1.31613864e-02, -3.44647691e-02,\n",
              "        -7.06138648e-03,  1.24527104e-02,  8.55674893e-02,\n",
              "         5.42758666e-02, -3.89169306e-02, -7.57954568e-02,\n",
              "        -1.40139246e-02,  1.48370573e-02,  9.68214422e-02,\n",
              "        -1.03704751e-01,  3.29137035e-02, -6.21125214e-02,\n",
              "         1.86114684e-02, -2.82176714e-02, -7.13014044e-03,\n",
              "         4.11865814e-03, -8.93324837e-02, -5.72975837e-02,\n",
              "         4.44727875e-02,  2.29126159e-02,  4.30734176e-03,\n",
              "        -6.96439147e-02, -6.36359379e-02, -2.61848141e-02,\n",
              "        -6.48371354e-02, -9.65941399e-02,  5.09348102e-02,\n",
              "        -8.90865400e-02, -3.94752212e-02, -2.23109834e-02,\n",
              "        -2.93313917e-02,  3.75236645e-02,  4.67261262e-02,\n",
              "         8.62412006e-02, -2.14183833e-02, -5.29951677e-02,\n",
              "         5.89277968e-02,  1.65255535e-02, -1.04241604e-02,\n",
              "        -2.38159820e-02,  1.38605135e-02,  2.62650289e-02,\n",
              "         5.47960065e-02, -4.24158424e-02,  3.17359809e-03,\n",
              "        -3.96554433e-02, -7.35217705e-02,  2.73186178e-03,\n",
              "        -2.72396160e-03, -3.98468412e-02, -4.29545231e-02,\n",
              "         2.14427691e-02,  3.84629257e-02,  3.88851948e-02,\n",
              "         5.13685122e-03, -4.95571420e-02, -3.24903801e-02,\n",
              "         2.83540115e-02, -4.67896871e-02,  1.97179038e-02,\n",
              "        -4.20575328e-02, -7.54898712e-02, -1.03865087e-03,\n",
              "        -6.73990920e-02,  3.91278379e-02,  4.40352149e-02,\n",
              "        -8.06924477e-02, -2.36365162e-02,  5.99047393e-02,\n",
              "         2.12467299e-03,  2.21580286e-02,  4.36153375e-02,\n",
              "         2.49224389e-03,  4.98777302e-03,  7.48325791e-03,\n",
              "        -2.41463762e-02,  4.05476056e-02,  2.91890763e-02,\n",
              "        -1.10162757e-02, -5.65643236e-02, -6.73807561e-02,\n",
              "         4.05558571e-02, -8.50009471e-02, -5.40723391e-02,\n",
              "         7.34481812e-02, -7.35007897e-02,  7.54500693e-03,\n",
              "        -7.00687617e-02,  4.39716317e-02, -2.71130353e-02,\n",
              "        -6.92854896e-02, -2.58241799e-02,  3.92786488e-02,\n",
              "         5.67648523e-02,  1.59089062e-02,  2.35409923e-02,\n",
              "        -5.06520756e-02,  1.17192315e-02, -6.92344606e-02,\n",
              "         1.38217909e-02,  1.09325163e-02,  7.00728744e-02,\n",
              "        -1.26282955e-02,  7.97541216e-02, -3.13802995e-02,\n",
              "        -4.11442295e-02, -3.50070819e-02, -4.26069386e-02,\n",
              "         4.05676849e-02,  7.93018341e-02, -9.75148231e-02,\n",
              "        -1.42815690e-02,  2.42777523e-02, -7.38641843e-02,\n",
              "        -1.56749655e-02, -3.48734371e-02, -5.93835153e-02,\n",
              "        -4.12432402e-02, -4.60708188e-03,  3.71532813e-02,\n",
              "         2.14900505e-02,  5.58095239e-02,  2.14638896e-02,\n",
              "        -6.75328448e-02,  1.01268652e-03,  5.95024973e-02,\n",
              "         1.24681811e-03,  3.76901776e-02,  4.18491475e-02,\n",
              "        -2.79387571e-02, -4.01746221e-02, -8.21424741e-03,\n",
              "        -5.58206253e-02, -1.60544664e-02, -4.75718342e-02,\n",
              "        -5.95801845e-02, -1.01037398e-02, -7.33451918e-02,\n",
              "        -1.84457749e-02,  3.76495942e-02, -8.28180164e-02,\n",
              "         7.54494919e-03, -2.76730023e-02, -3.70695628e-02,\n",
              "        -4.07461822e-02,  7.34209735e-03, -3.86686949e-03,\n",
              "        -1.10412011e-05,  3.76898311e-02,  1.45605989e-02,\n",
              "         2.78663402e-03, -6.57308921e-02, -2.55980752e-02,\n",
              "        -4.81109768e-02,  1.18657304e-02, -2.13191174e-02,\n",
              "         3.31167597e-03,  4.66567464e-02,  4.63188030e-02,\n",
              "        -3.60700078e-02, -7.05618784e-02, -7.14360103e-02,\n",
              "        -9.04084649e-03,  2.11612061e-02, -4.92307991e-02,\n",
              "         3.87155674e-02,  7.73286670e-02,  1.89448930e-02,\n",
              "         3.85826603e-02, -6.83923662e-02, -5.28842285e-02,\n",
              "         8.54228511e-02,  1.28640132e-02,  2.20266152e-02,\n",
              "         2.16054935e-02,  5.56524261e-04,  1.64826326e-02,\n",
              "        -3.31564508e-02,  8.13280120e-02, -2.25724354e-02,\n",
              "        -4.43336032e-02,  7.10498765e-02, -8.87572765e-02,\n",
              "         5.36287874e-02, -6.93188384e-02, -2.98250909e-03,\n",
              "         4.52212542e-02,  4.61279713e-02,  3.65344696e-02,\n",
              "         4.84847277e-02, -2.92588454e-02,  7.36932978e-02,\n",
              "         3.66693437e-02, -6.80679232e-02,  3.96357896e-03,\n",
              "        -9.04875994e-02, -6.32659867e-02, -5.38307689e-02,\n",
              "         6.08243048e-02, -1.84412617e-02,  4.89365570e-02,\n",
              "        -5.12656905e-02, -1.50805665e-02, -5.71211707e-03,\n",
              "        -5.10706753e-02, -6.49115220e-02, -1.13349990e-03,\n",
              "         1.27703352e-02,  1.82183385e-02, -8.28226283e-02,\n",
              "         2.10517365e-03, -3.31831500e-02,  5.95651940e-02,\n",
              "         3.61991301e-02,  5.35384603e-02, -2.25340612e-02,\n",
              "         2.64133271e-02, -3.91572639e-02, -5.87077662e-02,\n",
              "        -1.03312612e-01,  7.45007012e-04,  1.97312534e-02,\n",
              "         3.94937098e-02,  9.22513306e-02, -2.05244739e-02,\n",
              "         2.21597683e-02, -3.13704386e-02, -1.32243969e-02,\n",
              "         4.00840417e-02, -1.50230015e-02,  6.54290244e-02,\n",
              "        -6.08944222e-02,  7.63108605e-04, -3.62863205e-02,\n",
              "         4.91616353e-02, -6.04683273e-02, -1.77060235e-02,\n",
              "         2.45513860e-03, -4.52068113e-02,  3.63887809e-02,\n",
              "        -9.97238010e-02, -2.95221955e-02,  8.41338839e-03,\n",
              "        -8.18829611e-02,  1.82565190e-02,  1.11088129e-02,\n",
              "        -3.46704014e-02, -1.07370354e-02, -4.20162529e-02,\n",
              "        -2.58049592e-02,  3.06181461e-02,  1.86228193e-02,\n",
              "         2.78461538e-03, -3.67321074e-03,  5.00444286e-02,\n",
              "        -2.75492519e-02,  4.84464429e-02,  7.04697818e-02,\n",
              "         9.36839655e-02,  2.49331277e-02, -4.27237116e-02,\n",
              "        -3.15812081e-02, -4.44082841e-02, -3.41433510e-02,\n",
              "         2.81602852e-02, -8.78944062e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoder_layer=hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                                                    input_shape=[],\n",
        "                                                                    dtype=tf.string,\n",
        "                                                                    trainable=True,\n",
        "                                                                    name=\"USE\"\n",
        "                                                                    )\n"
      ],
      "metadata": {
        "id": "K8wzZwSc6ota"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    # tf.keras.layers.Reshape((1, -1)),\n",
        "    # tf.keras.layers.GRU(64),\n",
        "    tf.keras.layers.Dense(4,activation='softmax')\n",
        "],name='model_6_USE')\n",
        "model_6.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                            optimizer=tf.keras.optimizers.Adam(0.00001),\n",
        "                            metrics=['accuracy']\n",
        "                                )\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0otIgtgX7dco",
        "outputId": "ed345f34-ec59-492c-ee52-0eb5ec1a992c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,799,876\n",
            "Trainable params: 256,799,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_10_percent_split=int(0.5*len(train_sentences))\n",
        "train_sentences_10_percent=train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent=train_labels[:train_10_percent_split]\n",
        "\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXDg-ft7Bhtz",
        "outputId": "319627e5-705b-4051-9d27-260dd6ff7635"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    8016\n",
              "2    3291\n",
              "0    2635\n",
              "3    1438\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_history=model_6.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaEAulVA_RWt",
        "outputId": "bd78daa2-c59e-4077-b3e5-166b6f78c39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "481/481 [==============================] - 53s 111ms/step - loss: 0.3478 - accuracy: 0.8799 - val_loss: 0.6882 - val_accuracy: 0.7315\n",
            "Epoch 2/5\n",
            "481/481 [==============================] - 52s 108ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.9548 - val_accuracy: 0.7171\n",
            "Epoch 3/5\n",
            "481/481 [==============================] - 49s 102ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 1.0031 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "481/481 [==============================] - 59s 122ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 1.1119 - val_accuracy: 0.7348\n",
            "Epoch 5/5\n",
            "481/481 [==============================] - 50s 104ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 1.1793 - val_accuracy: 0.7154\n"
          ]
        }
      ]
    }
  ]
}